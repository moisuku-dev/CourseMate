# -*- coding: utf-8 -*-
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
from torch import nn
from transformers import BertModel, AutoTokenizer
import uvicorn
import json
import os
import re

# ==========================================
# 1. ê²½ë¡œ ë° í™˜ê²½ ì„¤ì • (í´ë” êµ¬ì¡° ë°˜ì˜)
# ==========================================
# í˜„ì¬ íŒŒì¼(main.py)ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œë¥¼ ì¡ìŠµë‹ˆë‹¤.
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: src í´ë” ë°–ìœ¼ë¡œ ë‚˜ê°€ì„œ(..) models í´ë”ë¡œ ì§„ì…
MODEL_FILE = os.path.join(BASE_DIR, "../models/course_mate_model.pt")

# íƒœê·¸ íŒŒì¼ ê²½ë¡œ: src í´ë” ì•ˆì— ê°™ì´ ìˆìŒ
TAGS_FILE = os.path.join(BASE_DIR, "tags.json")

# ì„¤ì •ê°’
MODEL_NAME = "klue/bert-base"
MAX_LEN = 128
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
SERVER_PORT = 65030  # ğŸš¨ í•™êµ íŒ€ ì „ìš© í¬íŠ¸

# ==========================================
# 2. íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
# ==========================================
if not os.path.exists(TAGS_FILE):
    print(f"âŒ ì˜¤ë¥˜: '{TAGS_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    print("   -> tags.json íŒŒì¼ì´ main.pyì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit()

with open(TAGS_FILE, "r", encoding="utf-8") as f:
    FINAL_TAGS = json.load(f)
print(f"âœ… íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ! (ì´ {len(FINAL_TAGS)}ê°œ)")

# ==========================================
# 3. ì „ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================
def clean_text(text):
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s.,!?]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# ==========================================
# 4. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
# ==========================================
class KoBERTClass(nn.Module):
    def __init__(self, num_labels):
        super(KoBERTClass, self).__init__()
        self.bert = BertModel.from_pretrained(MODEL_NAME)
        self.classifier = nn.Linear(768, num_labels)

    def forward(self, input_ids, attention_mask, token_type_ids):
        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
        return self.classifier(output.pooler_output)

# ==========================================
# 5. ì„œë²„ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ
# ==========================================
app = FastAPI(title="CourseMate AI Server")

print(f"â³ AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤... (ê²½ë¡œ: {MODEL_FILE})")
try:
    model = KoBERTClass(len(FINAL_TAGS))
    model.load_state_dict(torch.load(MODEL_FILE, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! AIê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("   -> Tip: '../models/course_mate_model.pt' ê²½ë¡œì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit()

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# ==========================================
# 6. API ì—”ë“œí¬ì¸íŠ¸
# ==========================================
class ReviewRequest(BaseModel):
    review: str  # ë°±ì—”ë“œ ìš”ì²­ í‚¤ê°’ ("review")

@app.post("/analyze/review")
async def analyze_review(request: ReviewRequest):
    origin_text = request.review
    
    # 1. ì „ì²˜ë¦¬
    cleaned_text = clean_text(origin_text)
    
    # 2. í† í¬ë‚˜ì´ì§•
    inputs = tokenizer.encode_plus(
        cleaned_text, None, add_special_tokens=True, max_length=MAX_LEN,
        padding='max_length', return_token_type_ids=True, truncation=True
    )

    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0).to(DEVICE)
    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0).to(DEVICE)
    token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).unsqueeze(0).to(DEVICE)

    # 3. ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(ids, mask, token_type_ids)
    
    probs = torch.sigmoid(outputs).cpu().numpy()[0]
    
    # 4. ê²°ê³¼ ì •ë¦¬
    results = []
    for i, prob in enumerate(probs):
        if prob > 0.5:
            results.append({
                "tag": FINAL_TAGS[i],
                "score": round(float(prob), 4)
            })
            
    # 5. ë°˜í™˜
    return {
        "result_code": 200,
        "detected_tags": results
    }

# ==========================================
# 7. ì„œë²„ ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    print(f"ğŸš€ AI ì„œë²„ ê°€ë™ ì‹œì‘! í¬íŠ¸: {SERVER_PORT}")
    uvicorn.run(app, host="0.0.0.0", port=SERVER_PORT)
